"""
ml_pipeline_no_xgboost.py

This script demonstrates an end-to-end machine learning workflow on an HDInsight Spark cluster
using PySpark’s MLlib. It covers:

  - Synthetic data generation for regression and classification
  - Feature engineering using Spark’s Pipeline API (with StringIndexer, OneHotEncoder, VectorAssembler,
    StandardScaler, and PCA)
  - Training a regression model with Gradient Boosted Trees (GBTRegressor)
  - Training a classification model with RandomForestClassifier
  - Hyperparameter tuning with CrossValidator and ParamGridBuilder
  - Logging metrics and models using MLflow
  - An example of distributed inference with a broadcast join

Before running, ensure that:
  - MLflow is installed in your Python environment.
  - Your environment is configured to connect to your HDInsight cluster (e.g. HADOOP_CONF_DIR is set).
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import rand, when, col, broadcast

# Import pipeline components
from pyspark.ml import Pipeline
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler, PCA

# Regression model and evaluator
from pyspark.ml.regression import GBTRegressor
from pyspark.ml.evaluation import RegressionEvaluator

# Classification model and evaluators (using RandomForest)
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator

# Hyperparameter tuning components
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder

# MLflow for experiment tracking
import mlflow
import mlflow.spark
# Create Spark session connecting to YARN (HDInsight)
spark = SparkSession.builder \
    .appName("HDInsight_ML_Pipeline_No_XGBoost") \
    .master("yarn") \
    .getOrCreate()

# -------------------------------
# Section 1: Data Generation
# -------------------------------

# Regression Dataset:
#  - Two numeric features ("feature1" and "feature2")
#  - One categorical feature ("category")
#  - Target is a linear combination of the numeric features plus noise
regression_df = (
    spark.range(0, 1000000)
        .withColumn("feature1", rand() * 100)
        .withColumn("feature2", rand() * 50)
        .withColumn("category", when(rand() > 0.5, "A").otherwise("B"))
        .withColumn("target", col("feature1") * 2.5 + col("feature2") * -1.5 + (rand() * 10))
)
regression_df = regression_df.repartition(10).cache()

# Classification Dataset:
#  - Two numeric features ("feat1" and "feat2")
#  - One categorical feature ("cat_feature")
#  - Binary label ("label") generated by a threshold condition
classification_df = (
    spark.range(0, 1000000)
        .withColumn("feat1", rand() * 10)
        .withColumn("feat2", rand() * 5)
        .withColumn("cat_feature", when(rand() > 0.5, "X").otherwise("Y"))
        .withColumn("label", when((col("feat1") + col("feat2") + rand() * 5) > 10, 1).otherwise(0))
)
classification_df = classification_df.repartition(10).cache()

# ---------------------------------------
# Section 2: Feature Engineering Pipelines
# ---------------------------------------

# Regression Pipeline: Assemble numeric features, scale them, and apply PCA.
reg_numeric_cols = ["feature1", "feature2"]
assembler_reg = VectorAssembler(inputCols=reg_numeric_cols, outputCol="num_features")
scaler_reg = StandardScaler(inputCol="num_features", outputCol="scaled_features")
pca_reg = PCA(k=2, inputCol="scaled_features", outputCol="pca_features")
reg_pipeline = Pipeline(stages=[assembler_reg, scaler_reg, pca_reg])

# Classification Pipeline: Index and one-hot encode the categorical feature, then assemble with numeric features.
indexer = StringIndexer(inputCol="cat_feature", outputCol="cat_index")
encoder = OneHotEncoder(inputCols=["cat_index"], outputCols=["cat_encoded"])
assembler_clf = VectorAssembler(inputCols=["feat1", "feat2", "cat_encoded"], outputCol="features")
clf_pipeline = Pipeline(stages=[indexer, encoder, assembler_clf])

# -------------------------------------------------
# Section 3: Regression Model Training with GBT
# -------------------------------------------------
with mlflow.start_run(run_name="Regression_GBT"):
    reg_prepared = reg_pipeline.fit(regression_df).transform(regression_df)
    train_reg, test_reg = reg_prepared.randomSplit([0.8, 0.2], seed=42)

    gbt = GBTRegressor(featuresCol="pca_features", labelCol="target", maxIter=20)
    paramGrid_reg = (ParamGridBuilder()
                     .addGrid(gbt.maxDepth, [3, 5])
                     .addGrid(gbt.maxIter, [10, 20])
                     .build())

    cv_reg = CrossValidator(estimator=gbt,
                            estimatorParamMaps=paramGrid_reg,
                            evaluator=RegressionEvaluator(labelCol="target", metricName="rmse"),
                            numFolds=3)
    reg_cv_model = cv_reg.fit(train_reg)

    predictions_reg = reg_cv_model.transform(test_reg)
    evaluator_reg = RegressionEvaluator(labelCol="target", metricName="rmse")
    rmse = evaluator_reg.evaluate(predictions_reg)

    mlflow.log_metric("reg_rmse", rmse)
    mlflow.spark.log_model(reg_cv_model.bestModel, "regression_model")

    print(f"Regression Model RMSE: {rmse}")

# ----------------------------------------------------
# Section 4: Classification Model Training with RF
# ----------------------------------------------------
with mlflow.start_run(run_name="Classification_RandomForest"):
    clf_prepared = clf_pipeline.fit(classification_df).transform(classification_df)
    train_clf, test_clf = clf_prepared.randomSplit([0.8, 0.2], seed=42)

    rf = RandomForestClassifier(featuresCol="features", labelCol="label", numTrees=20)
    paramGrid_clf = (ParamGridBuilder()
                     .addGrid(rf.maxDepth, [3, 5])
                     .addGrid(rf.numTrees, [10, 20])
                     .build())

    cv_clf = CrossValidator(estimator=rf,
                            estimatorParamMaps=paramGrid_clf,
                            evaluator=BinaryClassificationEvaluator(labelCol="label", metricName="areaUnderROC"),
                            numFolds=3)
    rf_cv_model = cv_clf.fit(train_clf)

    predictions_clf = rf_cv_model.transform(test_clf)
    evaluator_clf = BinaryClassificationEvaluator(labelCol="label", metricName="areaUnderROC")
    auc = evaluator_clf.evaluate(predictions_clf)
    multi_eval = MulticlassClassificationEvaluator(labelCol="label", metricName="accuracy")
    accuracy = multi_eval.evaluate(predictions_clf)

    mlflow.log_metric("clf_auc", auc)
    mlflow.log_metric("clf_accuracy", accuracy)
    mlflow.spark.log_model(rf_cv_model.bestModel, "classification_model")

    print(f"Classification Model AUC: {auc}, Accuracy: {accuracy}")

# -----------------------------------------------------------
# Section 5: Distributed Inference Example (Broadcast Join)
# -----------------------------------------------------------
lookup_data = [("A", 1), ("B", 2)]
lookup_df = spark.createDataFrame(lookup_data, ["category", "lookup_value"])
joined_df = regression_df.join(broadcast(lookup_df), on="category", how="left")
joined_df = joined_df.cache()
joined_df.show(5)

# Stop the Spark session when done.
spark.stop()
